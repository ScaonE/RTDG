{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homemade \"taxonomic assignment\" with blast+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which results are unique to nr / unique to plant_refseq ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goals \n",
    "- Sort contigs based on the subject taxonomy of their best blast+ hit.\n",
    "- This will help create a reference transcriptome for Douglas Pine (thx to UGMA RNA-seq data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hess : blastx vs plant_refseq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Existing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be used for solving similar questions :\n",
    "- http://qiime.org/scripts/assign_taxonomy.html\n",
    "- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4186660"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Existing transcriptomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data were retrieved from Stephanie. <br>\n",
    "Below are available urls to DL the same data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "# PineRefSeq (2008)\n",
    "axel -q http://dendrome.ucdavis.edu/ftp/Genome_Data/genome/\\\n",
    "pinerefseq/Psme/v1.0/gene_models/Psme.allgenes.transcripts.fasta;\n",
    "mv Psme.allgenes.transcripts.fasta pinerefseq.fasta;\n",
    "pigz pinerefseq.fasta;\n",
    "\n",
    "# Lorenz et al. (2012)\n",
    "# lorenz_mira.fasta.gz, lorenz_nblr.fasta.gz & lorenz_ngen.fasta.gz\n",
    "\n",
    "# MÃ¼ller et al. (2012)\n",
    "# muller.fasta.gz\n",
    "\n",
    "# Howe et al. (2013)\n",
    "axel -q ftp://ftp.ncbi.nlm.nih.gov/sra/wgs_aux/GA/EK/GAEK01/GAEK01.1.fsa_nt.gz;\n",
    "mv GAEK01.1.fsa_nt.gz howe.fasta.gz;\n",
    "\n",
    "# Little et al. (2016)\n",
    "axel -q ftp://ftp.ncbi.nlm.nih.gov/sra/wgs_aux/GA/ZW/GAZW02/GAZW02.1.fsa_nt.gz;\n",
    "axel -q ftp://ftp.ncbi.nlm.nih.gov/sra/wgs_aux/GA/ZW/GAZW02/GAZW02.2.fsa_nt.gz;\n",
    "cat GAZW02.1.fsa_nt.gz GAZW02.2.fsa_nt.gz > little.fasta.gz;\n",
    "rm GAZW02.1.fsa_nt.gz GAZW02.2.fsa_nt.gz;\n",
    "\n",
    "# Hess et al. (2016)\n",
    "axel -q ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE73nnn/GSE73420/suppl/GSE73420_PUT_set.fasta.gz;\n",
    "mv GSE73420_PUT_set.fasta.gz hess.fasta.gz;\n",
    "\n",
    "# Merge of those 6 transcriptomes with cdhitest (0.99%)\n",
    "# all_ref_cdhitest.fasta.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) UGMA data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data retrieved from Stephanie. <br>\n",
    "Correspond to a Trinity assembly on RNA-seq data. The RNA-seq data set was split in half (for memory issues), yielding 2 assemblies, which were subsequently merged into a single assembly  with CD-HIT-EST. <br>\n",
    "Ps : This first assembly was carried out by an intern. Stephanie is currently running a fresh assembly with known parameters on the latest version of Trinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Plant_refseq_prot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve plant_refseq_prot for future blastx :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/refseq/release/plant/*.protein.faa.gz &>> wget.verbose;\n",
    "cat *faa.gz > plant_ref_seq.faa.gz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) accession2taxid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve taxonomic informations from blastx output vs a custom subject database, we need to map the saccver column (accession) with a staxids (ncib taxonomy taxid). Querying this via esearch / esearch is slow because it create a lot of http requests. But thankfully, we have access to files named \"accession2taxid\" on ncbi ftp. They map saccver to staxids and we can use local unix commands to query them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "# Download both current prot.accession2taxid and older dead_prot.accession2taxid\n",
    "# given that plant_refseq_prot accession info may be outdated and only found in the older file\n",
    "axel -q ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/prot.accession2taxid.gz;\n",
    "axel -q ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/prot.accession2taxid.gz.md5;\n",
    "axel -q ftp://ftp.ncbi.nih.gov/pub/taxonomy/accession2taxid/dead_prot.accession2taxid.gz;\n",
    "axel -q ftp://ftp.ncbi.nih.gov/pub/taxonomy/accession2taxid/dead_prot.accession2taxid.gz.md5;\n",
    "# Check integrity\n",
    "for f in *.md5;\n",
    "do md5sum -c $f;\n",
    "done;\n",
    "# Merge them\n",
    "cat prot.accession2taxid dead_prot.accession2taxid > all_prot.accession2taxid.gz;\n",
    "rm *.md5 prot.accession2taxid.gz dead_prot.accession2taxid.gz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Rename contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid future collisions, given that some assemblies are the result of merges, we rename contigs to make sure that each contig name is unique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "# Add \"_1, _2, _3, etc...\" right after the \">\"\n",
    "for f in *.fasta.gz;\n",
    "do zcat $f \\\n",
    "   | awk '/^>/ {print \">\" ++i \"_\" substr($0,2); next}{print}' \\\n",
    "   > ${f%%.*}\"_renamed\".fasta;\n",
    "# Compress newly created FASTA files\n",
    "done;\n",
    "for f in *_renamed.fasta;\n",
    "do pigz $f;\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Assign contigs based on subject taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, we are using blast+_2.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get taxdb for blast+ locally (useful to directly retrieve staxids when database = nt or nr) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CODE ###\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/blast/db/taxdb.tar.gz;\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/blast/db/taxdb.tar.gz.md5;\n",
    "for f in *.md5;\n",
    "do tmp=$(md5sum -c $f);\n",
    "   if [[ $tmp == *\": OK\" ]];\n",
    "   then tar -zxvf  ${f%.*};\n",
    "        rm $f ${f%.*};\n",
    "   fi;\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ps : Don't forget to move tax files in the same dir as your other databases (nt, nr, etc...).<br>\n",
    "And don't forget to add the BLASTDB variable to your .bashrc (export BLASTDB = 'your_path)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Blastn vs nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to blast assembled contigs vs nt and afterwards check if contigs matched vs a plant sequence, a non-plant sequence or nothing. It's one of the first step to \"filter\" the raw/draft transcriptome assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CODE ###\n",
    "biscem='/home/erwann/Desktop/RTDG/BISCEm';\n",
    "cd $biscem/Data;\n",
    "blast='/home/erwann/Software/Blast_2.7.1/bin';\n",
    "db='/home/erwann/Software/ncbi-blast-2.5.0+/blastdb';\n",
    "for id in 'hess';\n",
    "do unpigz $id.fasta.gz;\n",
    "   $blast/blastn -query $id.fasta \\\n",
    "                 -db $db/nt \\\n",
    "                 -out $biscem/Output/$id'_vs_nt.tsv' \\\n",
    "                 -outfmt \"6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send \\\n",
    "                          evalue bitscore qlen slen saccver staxids sskingdoms sblastnames stitle\" \\\n",
    "                 -num_threads 8 \\\n",
    "                 -culling_limit 1;\n",
    "   pigz $id.fasta;\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Parse blastn result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nb : The idea on how to check if a contig matched to plant with the staxids field came from this post : https://www.biostars.org/p/163595/#163603. <br>\n",
    "\n",
    "What it does basically is :<br>\n",
    "\"staxids\" allows us to query the NCBI taxonomy database for the lineage of a taxon information with the tool eutils.<br>\n",
    "We can then parse this eutils xml result to check if kingdom <=> \"Viridiplantae\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, a dummy example for staxids = 3357 (Pseudotsuga menziesii <=> Douglas) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3357@Pseudotsuga menziesii\tsuperkingdom@Eukaryota\tkingdom@Viridiplantae\tphylum@Streptophyta\torder@Pinales\tfamily@Pinaceae\tgenus@Pseudotsuga\n"
     ]
    }
   ],
   "source": [
    "#### CODE ###\n",
    "# Retrive \"RECOFGE\" + superkingdom, in this order : E_SK_R_E_C_O_F_G\n",
    "efetch -db taxonomy \\\n",
    "       -id 3357 \\\n",
    "       -format xml \\\n",
    "       | xtract -pattern Taxon \\\n",
    "                  -sep '@' \\\n",
    "                  -element TaxId,ScientificName \\\n",
    "                -division LineageEx \\\n",
    "                -group Taxon \\\n",
    "                  -if Rank -equals superkingdom \\\n",
    "                  -or Rank -equals kingdom \\\n",
    "                  -or Rank -equals phylum \\\n",
    "                  -or Rank -equals class \\\n",
    "                  -or Rank -equals order \\\n",
    "                  -or Rank -equals family \\\n",
    "                  -or Rank -equals genus \\\n",
    "                    -sep '@' \\\n",
    "                    -element Rank,ScientificName;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sort_plant_hit_vs_nt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CODE ###\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "usage = '\\t --------\\n' \\\n",
    "        '\\t| usage  : python sort_plant_hit_vs_nt.py f1 f2\\n' \\\n",
    "        '\\t| input  : f1 = blastn.tsv (vs nt)\\n' \\\n",
    "        '\\t| input  : f2 = seqs.fasta (blastn queries)\\n' \\\n",
    "        '\\t| output : \"f2\"_1.fasta (plant_hit)\\n' \\\n",
    "        '\\t| output : \"f2\"_2.fasta (non_plant_hit)\\n' \\\n",
    "        '\\t| output : \"f2\"_3.fasta (no_hit)\\n' \\\n",
    "        '\\t --------'\n",
    "\n",
    "if len(sys.argv) != 3:\n",
    "    print(usage)\n",
    "    sys.exit()\n",
    "\n",
    "##############\n",
    "### Step 1 ###\n",
    "##############\n",
    "print('\\n\\tStep 1) Retrieve taxonomic infos for each staxids with efetch')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# For each line in TSV (f1), fill staxids_set\n",
    "staxids_set = set()\n",
    "with open(sys.argv[1], 'r') as tsv:\n",
    "    for row in tsv:\n",
    "        columns = row.split('\\t')\n",
    "        # Sometimes you have more than one staxids for an entry\n",
    "        staxids = columns[15].split(';')\n",
    "        for i in staxids:\n",
    "            staxids_set.add(i)\n",
    "\n",
    "# Use staxids_set as query with efetch & store result\n",
    "# Don't give more than let's say 500 entries at a time to avoid timeout\n",
    "staxids_li = list(staxids_set)\n",
    "staxids_sub_li = [staxids_li[x:x + 500]\n",
    "                  for x in range(0, len(staxids_li), 500)]\n",
    "efetch_li = []\n",
    "for item in staxids_sub_li:\n",
    "    staxids_input = ','.join(str(z) for z in item)\n",
    "    # Details about \"cmd\" : https://www.biostars.org/p/163595/#271497\n",
    "    cmd = ('efetch -db taxonomy -id ' + staxids_input + ' -format xml | xtract '\n",
    "           '-pattern Taxon -sep \\'@\\' -element TaxId,ScientificName -division '\n",
    "           'LineageEx -group Taxon -if Rank -equals superkingdom -or Rank '\n",
    "           '-equals kingdom -or Rank -equals phylum -or Rank -equals class'\n",
    "           ' -or Rank -equals order -or Rank -equals family -or Rank -equals'\n",
    "           ' genus -sep \\'@\\' -element Rank,ScientificName')\n",
    "    cmd_result = os.popen(cmd).read()\n",
    "    cmd_result_split = cmd_result.split('\\n')\n",
    "    for i in cmd_result_split:\n",
    "        efetch_li.append(i)\n",
    "\n",
    "# Create a dict associating key=staxid with value=list=tax_infos\n",
    "taxonomy_dic = {}\n",
    "for line in efetch_li:\n",
    "    field = line.split('\\t')\n",
    "    tax_ids = field[0].split('@')\n",
    "    # Sometimes more than one staxid is associated to an entry\n",
    "    # e.g. \"170850@3666@Cucurbita hybrid cultivar\"\n",
    "    for i in tax_ids[:-1]:\n",
    "        taxonomy_dic.setdefault(i, [None, None, None, None, None, None, None])\n",
    "        for item in field:\n",
    "            if 'superkingdom@' in item:\n",
    "                taxonomy_dic[i][0] = item.split('@')[-1]\n",
    "            elif 'kingdom@' in item:\n",
    "                taxonomy_dic[i][1] = item.split('@')[-1]\n",
    "            elif 'phylum@' in item:\n",
    "                taxonomy_dic[i][2] = item.split('@')[-1]\n",
    "            elif 'class@' in item:\n",
    "                taxonomy_dic[i][3] = item.split('@')[-1]\n",
    "            elif 'order@' in item:\n",
    "                taxonomy_dic[i][4] = item.split('@')[-1]\n",
    "            elif 'family@' in item:\n",
    "                taxonomy_dic[i][5] = item.split('@')[-1]\n",
    "            elif 'genus@' in item:\n",
    "                taxonomy_dic[i][6] = item.split('@')[-1]\n",
    "\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "##############\n",
    "### Step 2 ###\n",
    "##############\n",
    "print('\\tStep 2) Assign contigs best hit to plant or non-plant')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Assign contigs best hits to plant or non-plant based on taxonomy_dic infos\n",
    "qseqid_set, viridi_hit_set, non_viridi_hit_set = set(), set(), set()\n",
    "with open(sys.argv[1], 'r') as tsv:\n",
    "    for row in tsv:\n",
    "        columns = row.split('\\t')\n",
    "        qseqid, staxids = columns[0], columns[15].split(';')[0]\n",
    "        # Check if we encounter qseqid for the first time <=> best hit\n",
    "        if not qseqid in qseqid_set:\n",
    "            if taxonomy_dic[staxids][1] == 'Viridiplantae':\n",
    "                viridi_hit_set.add(qseqid)\n",
    "            else:\n",
    "                non_viridi_hit_set.add(qseqid)\n",
    "        qseqid_set.add(qseqid)\n",
    "\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "##############\n",
    "### Step 3 ###\n",
    "##############\n",
    "print('\\tStep 3) Find contigs with no hits')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Read initial FASTA (f2) & check intersection with viridi_hit_set & non_viridi_hit_set\n",
    "# We can deduce contigs with no hit from this intersection\n",
    "cpt = 0\n",
    "no_hit_set = set()\n",
    "with open(sys.argv[2], 'r') as fa:\n",
    "    for line in fa:\n",
    "        if line.startswith('>'):\n",
    "            cpt += 1\n",
    "            line = line.lstrip('>')\n",
    "            fields = line.split()\n",
    "            no_hit_set.add(fields[0])\n",
    "\n",
    "before_union = len(no_hit_set)\n",
    "no_hit_set = no_hit_set - viridi_hit_set\n",
    "no_hit_set = no_hit_set - non_viridi_hit_set\n",
    "\n",
    "print('\\t\\t- number of seqs (>) in FASTA : ' + str(cpt))\n",
    "print('\\t\\t- number of headers added to initial set is ' + str(before_union))\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "##############\n",
    "### Step 4 ###\n",
    "##############\n",
    "print('\\tStep 4) Create output files')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Create input files (sequence IDs list) for seqtk\n",
    "file_2 = sys.argv[2].split('/')\n",
    "sample = file_2[-1].split('.')[0]\n",
    "with open(sample + '_plant_hit.temp', 'w') as out:\n",
    "    for item in viridi_hit_set:\n",
    "        out.write(item + \"\\n\")\n",
    "with open(sample + '_non_plant_hit.temp', 'w') as out:\n",
    "    for item in non_viridi_hit_set:\n",
    "        out.write(item + \"\\n\")\n",
    "with open(sample + '_no_hit.temp', 'w') as out:\n",
    "    for item in no_hit_set:\n",
    "        out.write(item + \"\\n\")\n",
    "\n",
    "# Create output files (plant_hit = 1, non-plant_hit = 2, no-hit = 3) with seqtk\n",
    "os.system('seqtk subseq ' + sys.argv[2] + ' ' + sample +\n",
    "          '_plant_hit.temp > ' + sample + '_1.fasta')\n",
    "os.system('seqtk subseq ' + sys.argv[2] + ' ' + sample +\n",
    "          '_non_plant_hit.temp > ' + sample + '_2.fasta')\n",
    "os.system('seqtk subseq ' + sys.argv[2] + ' ' + sample +\n",
    "          '_no_hit.temp > ' + sample + '_3.fasta')\n",
    "\n",
    "sum_seqs = int(len(viridi_hit_set)) + int(len(non_viridi_hit_set)) + int(len(no_hit_set))\n",
    "print('\\t\\t- number of seqs with plant_hit : ' + str(len(viridi_hit_set)))\n",
    "print('\\t\\t- number of seqs in non_plant_hit : ' + str(len(non_viridi_hit_set)))\n",
    "print('\\t\\t- number of seqs with no_hit : ' + str(len(no_hit_set)))\n",
    "print('\\t\\t- sum of the 3 above : ' + str(sum_seqs))\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "os.system('rm *.temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What it does : <br>\n",
    "Take the blastn TVS file and the contig FASTA file as input.<br>\n",
    "Then check for each contig best hit if kingdom <=> \"Viridiplantae\".<br>\n",
    "If so, we consider the contig to have a plant hit (output file \"_1\").<br>\n",
    "Else, we consider the contig to have a non-plant hit (output file \"_2\").<br>\n",
    "Then, iterate other the contig file to collect contigs name & check intersection with contigs having plant / non-plant hits. This allow to determine contigs with no hits (output file \"_3\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the script :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tStep 1) Retrieve taxonomic infos for each staxids with efetch\n",
      "\t\t=> 35.252 seconds\n",
      "\n",
      "\tStep 2) Assign contigs best hit to plant or non-plant\n",
      "\t\t=> 0.534 seconds\n",
      "\n",
      "\tStep 3) Find contigs with no hits\n",
      "\t\t- number of seqs (>) in FASTA : 799102\n",
      "\t\t- number of headers added to initial set is 799102\n",
      "\t\t=> 3.132 seconds\n",
      "\n",
      "\tStep 4) Create output files\n",
      "\t\t- number of seqs with plant_hit : 98818\n",
      "\t\t- number of seqs in non_plant_hit : 92665\n",
      "\t\t- number of seqs with no_hit : 607619\n",
      "\t\t- sum of the 3 above : 799102\n",
      "\t\t=> 6.974 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### CODE ###\n",
    "biscem='/home/erwann/Desktop/RTDG/BISCEm';\n",
    "cd $biscem/Output;\n",
    "for id in 'trinity_cdhitest';\n",
    "do unpigz $biscem/Data/$id'_renamed.fasta.gz';\n",
    "   python $biscem/Git/sort_plant_hit_vs_nt.py $id'_renamed_vs_nt.tsv' $biscem/Data/$id'_renamed.fasta';\n",
    "   pigz $biscem/Data/$id'_renamed.fasta';\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was done for each known reference transcriptome + UGMA assemblies. Then basic stats were computed on output FASTA files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CODE ###\n",
    "for f in  hess*.fasta;\n",
    "do echo $f; perl ../Script/assemblyStats.pl $f;\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are compiled here : https://docs.google.com/spreadsheets/d/1hYWprws5gd2-W2vgMux2lVAtXx5TVm4IenuwZr6DcF4/edit#gid=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Blastx vs nr | plant_refseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is especially useful for contigs which have previously failed to be assigned to \"Viridiplantae\" vs nt. <br>\n",
    "Blastx vs a protein subject database may highlight more informative contigs. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1) Create DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "biscem='/home/erwann/Desktop/RTDG/BISCEm';\n",
    "blast='/home/erwann/Software/Blast_2.7.1/bin';\n",
    "unpigz $biscem/Data/plant_ref_seq.faa.gz;\n",
    "$blast/makeblastdb -in $biscem/Data/plant_ref_seq.faa -input_type fasta -dbtype prot -out plant_ref_seq;\n",
    "pigz $biscem/Data/plant_ref_seq.faa;\n",
    "mv plant_* /home/erwann/Software/ncbi-blast-2.5.0+/blastdb;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch actual blastx (vs plant_refseq) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "# Launch blastx\n",
    "biscem='/home/erwann/Desktop/RTDG/BISCEm';\n",
    "blast='/home/erwann/Software/Blast_2.7.1/bin';\n",
    "db='/home/erwann/Software/ncbi-blast-2.5.0+/blastdb';\n",
    "\n",
    "cd $biscem/Output;\n",
    "for id in 'trinity_cdhitest_renamed_2';\n",
    "do $blast/blastx -query $id.fasta \\\n",
    "                 -db $db/plant_ref_seq \\\n",
    "                 -out $id'_vs_plant_refseq_prot.tsv' \\\n",
    "                 -outfmt \"6 qseqid sseqid pident length mismatch gapopen qstart \\\n",
    "                          qend sstart send evalue bitscore qlen slen saccver\" \\\n",
    "                 -num_threads 8 \\\n",
    "                 -culling_limit 1;\n",
    "done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Parse blastx result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sort_plant_hit_vs_plant_refseq_prot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CODE ###\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "usage = '\\t --------\\n' \\\n",
    "        '\\t| usage  : python sort_plant_hit_vs_plant_refseq_prot.py f1 f2\\n' \\\n",
    "        '\\t| input  : f1 = blast.tsv (vs plant_ref_seq)\\n' \\\n",
    "        '\\t| input  : f2 = seqs.fasta (blastx queries)\\n' \\\n",
    "        '\\t| indir  : prot.accession2taxid.gz (to map saccver to staxids)\\n' \\\n",
    "        '\\t| output : \"f2\"_1.fasta (plant_hit)\\n' \\\n",
    "        '\\t| output : \"f2\"_2.fasta (non_plant_hit = a control here, should be empty)\\n' \\\n",
    "        '\\t| output : \"f2\"_3.fasta (no_hit)\\n' \\\n",
    "        '\\t --------'\n",
    "\n",
    "if len(sys.argv) != 3:\n",
    "    print(usage)\n",
    "    sys.exit()\n",
    "\n",
    "##############\n",
    "### Step 1 ###\n",
    "##############\n",
    "print('\\n\\tStep 1) Map saccver to staxids')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "cpt = 0\n",
    "qseqid_set, saccver_set = set(), set()\n",
    "with open(sys.argv[1], 'r') as tsv:\n",
    "    for row in tsv:\n",
    "        cpt += 1\n",
    "        columns = row.split('\\t')\n",
    "        qseqid, saccver = columns[0].rstrip(), columns[14].rstrip()\n",
    "        # Get rid of accession number version\n",
    "        saccver = saccver.split('.')[0]\n",
    "        if not qseqid in qseqid_set:\n",
    "            saccver_set.add(saccver)\n",
    "        qseqid_set.add(qseqid)\n",
    "\n",
    "# Use saccver_set as local query against prot.accession2taxid\n",
    "# create saccver.temp as input for grep\n",
    "with open('saccver.temp', 'w') as temp:\n",
    "    for item in saccver_set:\n",
    "        temp.write(item.rstrip() + \"\\n\")\n",
    "\n",
    "# map saccver to staxids\n",
    "cmd = 'zfgrep -f saccver.temp ../Data/all_prot.accession2taxid.gz'\n",
    "cmd_result = os.popen(cmd).read()\n",
    "# First attempt\n",
    "# cmd = ('zgrep -f saccver.temp prot.accession2taxid.gz | awk \\'{print $2\\\"\\t\\\"$3}\\' $_')\n",
    "# grep on unzipped file is faster (3.42 vs 5.28), but file is too big to please me\n",
    "# cmd = 'fgrep -f saccver.temp all_prot.accession2taxid'\n",
    "\n",
    "# store grep result in a temp file (easier to parse)\n",
    "with open('grep.temp', 'w') as temp:\n",
    "    temp.write(cmd_result)\n",
    "\n",
    "# Finally, map saccver to staxids in a dic\n",
    "saccver_to_staxids_dic = {}\n",
    "with open('grep.temp', 'r') as grep:\n",
    "    for line in grep:\n",
    "        field = line.split('\\t')\n",
    "        saccver_to_staxids_dic.setdefault(field[0].rstrip(), field[2].rstrip())\n",
    "\n",
    "print('\\t\\t- TSV have ' + str(cpt) + ' lines, containing ' +\n",
    "      str(len(saccver_set)) + ' unique saccver')\n",
    "print('\\t\\t- grep result contains ' + str(len(saccver_set)) + ' lines')\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "##############\n",
    "### Step 2 ###\n",
    "##############\n",
    "print('\\tStep 2) Retrieve taxonomic infos for each staxids with efetch')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Use staxids_set as query with efetch & store result\n",
    "# Don't give more than let's say 500 entries at a time to avoid timeout\n",
    "staxids_set = set()\n",
    "for k, v in saccver_to_staxids_dic.items():\n",
    "    staxids_set.add(v)\n",
    "\n",
    "staxids_li = list(staxids_set)\n",
    "staxids_sub_li = [staxids_li[x:x + 500]\n",
    "                  for x in range(0, len(staxids_li), 500)]\n",
    "efetch_li = []\n",
    "for item in staxids_sub_li:\n",
    "    staxids_input = ','.join(str(z) for z in item)\n",
    "    # Details about \"cmd\" : https://www.biostars.org/p/163595/#271497\n",
    "    cmd = ('efetch -db taxonomy -id ' + staxids_input + ' -format xml | xtract '\n",
    "           '-pattern Taxon -sep \\'@\\' -element TaxId,ScientificName -division '\n",
    "           'LineageEx -group Taxon -if Rank -equals superkingdom -or Rank '\n",
    "           '-equals kingdom -or Rank -equals phylum -or Rank -equals class'\n",
    "           ' -or Rank -equals order -or Rank -equals family -or Rank -equals'\n",
    "           ' genus -sep \\'@\\' -element Rank,ScientificName')\n",
    "    cmd_result = os.popen(cmd).read()\n",
    "    cmd_result_split = cmd_result.split('\\n')\n",
    "    for i in cmd_result_split:\n",
    "        efetch_li.append(i)\n",
    "# 257314@Lactobacillus johnsonii NCC\n",
    "# 533\\tsuperkingdom@Bacteria\\tphylum@Firmicutes\\tclass@Bacilli\\torder@Lactobacillales\\tfamily@Lactobacillaceae\\tgenus@Lactobacillus'\n",
    "\n",
    "# Create a dict associating key=staxid with value=list=tax_infos\n",
    "taxonomy_dic = {}\n",
    "for line in efetch_li:\n",
    "    field = line.split('\\t')\n",
    "    tax_ids = field[0].split('@')\n",
    "    # Sometimes more than one staxid is associated to an entry\n",
    "    # e.g. \"170850@3666@Cucurbita hybrid cultivar\"\n",
    "    for i in tax_ids[:-1]:\n",
    "        taxonomy_dic.setdefault(i, [None, None, None, None, None, None, None])\n",
    "        for item in field:\n",
    "            if 'superkingdom@' in item:\n",
    "                taxonomy_dic[i][0] = item.split('@')[-1]\n",
    "            elif 'kingdom@' in item:\n",
    "                taxonomy_dic[i][1] = item.split('@')[-1]\n",
    "            elif 'phylum@' in item:\n",
    "                taxonomy_dic[i][2] = item.split('@')[-1]\n",
    "            elif 'class@' in item:\n",
    "                taxonomy_dic[i][3] = item.split('@')[-1]\n",
    "            elif 'order@' in item:\n",
    "                taxonomy_dic[i][4] = item.split('@')[-1]\n",
    "            elif 'family@' in item:\n",
    "                taxonomy_dic[i][5] = item.split('@')[-1]\n",
    "            elif 'genus@' in item:\n",
    "                taxonomy_dic[i][6] = item.split('@')[-1]\n",
    "# '41840': ['Eukaryota', 'Viridiplantae', 'Streptophyta', 'Sphagnopsida', 'Sphagnales', 'Sphagnaceae', 'Sphagnum']\n",
    "\n",
    "print('\\t\\t- taxonomy_dic len is ' + str(len(taxonomy_dic)))\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "##############\n",
    "### Step 3 ###\n",
    "##############\n",
    "print('\\tStep 3) Assign contigs best hit to plant or non-plant')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Assign contigs best hits to plant or non-plant based on taxonomy_dic infos\n",
    "qseqid_set, viridi_hit_set, non_viridi_hit_set = set(), set(), set()\n",
    "with open(sys.argv[1], 'r') as tsv:\n",
    "    for row in tsv:\n",
    "        columns = row.split('\\t')\n",
    "        qseqid, saccver = columns[0].rstrip(), columns[14].rstrip()\n",
    "        # Get rid of accession number version\n",
    "        saccver = saccver.split('.')[0]\n",
    "        # Check if we encounter qseqid for the first time <=> best hit\n",
    "        if not qseqid in qseqid_set:\n",
    "            if taxonomy_dic[saccver_to_staxids_dic[saccver]][1] == 'Viridiplantae':\n",
    "                viridi_hit_set.add(qseqid)\n",
    "            else:\n",
    "                non_viridi_hit_set.add(qseqid)\n",
    "        qseqid_set.add(qseqid)\n",
    "\n",
    "print('\\t\\t- qseqid_set len is ' + str(len(qseqid_set)))\n",
    "print('\\t\\t- viridi_hit_set len is ' + str(len(viridi_hit_set)))\n",
    "print('\\t\\t- non_viridi_hit_set len is ' + str(len(non_viridi_hit_set)))\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "##############\n",
    "### Step 4 ###\n",
    "##############\n",
    "print('\\tStep 4) Find contigs with no hits')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Read initial FASTA (f2) & check intersection with viridi_hit_set & non_viridi_hit_set\n",
    "# We can deduce contigs with no hit from this intersection\n",
    "cpt = 0\n",
    "no_hit_set = set()\n",
    "with open(sys.argv[2], 'r') as fa:\n",
    "    for line in fa:\n",
    "        if line.startswith('>'):\n",
    "            cpt += 1\n",
    "            line = line.lstrip('>')\n",
    "            # if line in no_hit_set:\n",
    "            #    print(line)\n",
    "            # no_hit_set.add(line)\n",
    "            fields = line.split()\n",
    "            no_hit_set.add(fields[0])\n",
    "\n",
    "before_union = len(no_hit_set)\n",
    "no_hit_set = no_hit_set - viridi_hit_set\n",
    "no_hit_set = no_hit_set - non_viridi_hit_set\n",
    "\n",
    "print('\\t\\t- number of seqs (>) in FASTA : ' + str(cpt))\n",
    "print('\\t\\t- number of headers added to initial set is ' + str(before_union))\n",
    "print('\\t\\t- number of res in no_hit_set : ' + str(len(no_hit_set)))\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds\\n')\n",
    "\n",
    "\n",
    "##############\n",
    "### Step 5 ###\n",
    "##############\n",
    "print('\\tStep 5) Create output files')\n",
    "t0 = timeit.default_timer()\n",
    "\n",
    "# Create input files (sequence IDs list) for seqtk\n",
    "file_2 = sys.argv[2].split('/')\n",
    "sample = file_2[-1].split('.')[0]\n",
    "with open(sample + '_plant_hit.temp', 'w') as out:\n",
    "    for item in viridi_hit_set:\n",
    "        out.write(item + \"\\n\")\n",
    "with open(sample + '_non_plant_hit.temp', 'w') as out:\n",
    "    for item in non_viridi_hit_set:\n",
    "        out.write(item + \"\\n\")\n",
    "with open(sample + '_no_hit.temp', 'w') as out:\n",
    "    for item in no_hit_set:\n",
    "        field = item.split()\n",
    "        # out.write(item)\n",
    "        out.write(field[0] + '\\n')\n",
    "\n",
    "# Create output files (plant_hit = 1, non-plant_hit = 2, no-hit = 3) with seqtk\n",
    "os.system('seqtk subseq ' + sys.argv[2] + ' ' + sample +\n",
    "          '_plant_hit.temp > ' + sample + '_1.fasta')\n",
    "os.system('seqtk subseq ' + sys.argv[2] + ' ' + sample +\n",
    "          '_non_plant_hit.temp > ' + sample + '_2.fasta')\n",
    "os.system('seqtk subseq ' + sys.argv[2] + ' ' + sample +\n",
    "          '_no_hit.temp > ' + sample + '_3.fasta')\n",
    "\n",
    "sum_seqs = int(len(viridi_hit_set)) + \\\n",
    "    int(len(non_viridi_hit_set)) + int(len(no_hit_set))\n",
    "print('\\t\\t- number of seqs with plant_hit : ' + str(len(viridi_hit_set)))\n",
    "print('\\t\\t- number of seqs in non_plant_hit : ' + str(len(non_viridi_hit_set)))\n",
    "print('\\t\\t- number of seqs with no_hit : ' + str(len(no_hit_set)))\n",
    "print('\\t\\t- sum of the 3 above : ' + str(sum_seqs) +\n",
    "      ', which should be equal to : ' + str(cpt))\n",
    "print('\\t\\t=> ' + str(round(timeit.default_timer() - t0, 3)) + ' seconds')\n",
    "\n",
    "os.system('rm *.temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need an extra step compared to sort_plant_hit_vs_nt.py : <br>\n",
    "We need to map saccver to staxids, via the \"accession2taxid\" file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the script :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tStep 1) Map saccver to staxids\n",
      "\t\t- TSV have 80119 lines, containing 46660 unique saccver\n",
      "\t\t- grep result contains 46660 lines\n",
      "\t\t=> 218.973 seconds\n",
      "\n",
      "\tStep 2) Retrieve taxonomic infos for each staxids with efetch\n",
      "\t\t- taxonomy_dic len is 437\n",
      "\t\t=> 3.488 seconds\n",
      "\n",
      "\tStep 3) Assign contigs best hit to plant or non-plant\n",
      "\t\t- qseqid_set len is 55967\n",
      "\t\t- viridi_hit_set len is 55967\n",
      "\t\t- non_viridi_hit_set len is 0\n",
      "\t\t=> 0.255 seconds\n",
      "\n",
      "\tStep 4) Find contigs with no hits\n",
      "\t\t- number of seqs (>) in FASTA : 92665\n",
      "\t\t- number of headers added to initial set is 92665\n",
      "\t\t- number of res in no_hit_set : 36698\n",
      "\t\t=> 0.171 seconds\n",
      "\n",
      "\tStep 5) Create output files\n",
      "\t\t- number of seqs with plant_hit : 55967\n",
      "\t\t- number of seqs in non_plant_hit : 0\n",
      "\t\t- number of seqs with no_hit : 36698\n",
      "\t\t- sum of the 3 above : 92665, which should be equal to : 92665\n",
      "\t\t=> 0.403 seconds\n"
     ]
    }
   ],
   "source": [
    "### CODE ###\n",
    "biscem='/home/erwann/Desktop/RTDG/BISCEm';\n",
    "cd $biscem/Output;\n",
    "for id in 'trinity_cdhitest_renamed_2';\n",
    "do python $biscem/Git/sort_plant_hit_vs_plant_refseq_prot.py $id'_vs_plant_refseq_prot.tsv' $id.fasta;\n",
    "done;"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
